\section{Hashing\label{hashing}}
Words, URLs and every other {\it entity} stored
in \nr{} databases, is identified by an ID, in the
form of a fixed length cryptographic hash of the entity's
content.  Before hashing, the content is prefixed by the the
entity's own type name.

For example, the URL \url{https://example.com/} would be
identified by the hash of {\tt url:https://example.com/}.
The resulting ID is the first 12 bytes of the cleartext's
{\tt SHA-3} hash.  This hashing schema was chosen in order
to fulfil several requirements:
\begin{enumerate}
    \item The ability to know the ID of an entity without
          interacting with the database.\label{pre}
    \item Uniqueness of IDs across the entire
          database (over per-table uniqueness).\label{uniq}
    \item An infeasible hash collision rate among entities.\label{low}
\end{enumerate}
Requirement \ref{pre} ensures that small programs 
could reason about the data in the \nr{} system,
without necessarily needing a database connection in order to
obtain the ID of a word, or of a URL, or of anything else.
Knowing the ID of an entity before storing it is also
valuable in terms of concurrency and performance.  If a system
with a large amount of data were to rely on the auto-increment
feature (a popular `ID generator' in MySQL), then
huge amounts of communication to and from the database
would be needed in order for various machines to collaborate.

For example, in the tokenisation stage outlined in Section
\ref{clean}, several processes or machines are tokenising web
resources in parallel.  Most of the documents processed will
contain the word `{\it the}' at least once.  Relying on
auto-increment would lead each machine to send the following
SQL query to the database server:
`{\tt SELECT ID FROM Word WHERE value = `the';}'.
In any period of time, this costly ID check would need to be
carried out for each word in the lexicon of documents being
processed during that period.  Knowing with certainty that
the ID of `the' is {\tt A91A5E09C79E0221159C8DFF}, without
needing a database connection, is a highly valuable part of a
competitive IR service.

The choice of 12 bytes for the ID can be explained by
considering the birthday paradox and the pigeonhole principle.
If an IR service may potentially store billions of unique objects,
then the ID space needs to be in the region of trillions, to avoid
ID collisions (when two unrelated machines assign the same ID to
different objects).  This is illustrated in Figure \ref{bday}.  Using
12 byte IDs across different SQL tables renders a collision
practically impossible.

\begin{figure}
    \centering
    \singlespacing
    \begin{tabular}{r|l}
    Entities & Probability of collision\\
    \hline
    4,194,304               &   0.00000000000001\%\\
    8,388,608               &   0.00000000000004\%\\
    16,777,216              &   0.00000000000017\%\\
    33,554,432              &   0.00000000000071\%\\
    67,108,864              &   0.00000000000284\%\\
    134,217,728             &   0.00000000001136\%\\
    268,435,456             &   0.00000000004547\%\\
    536,870,912             &   0.00000000018189\%\\
    1,073,741,824           &   0.00000000072759\%\\
    2,147,483,648           &   0.00000000291038\%\\
    4,294,967,296           &   0.00000001164153\%\\
    8,589,934,592           &   0.00000004656612\%\\
    17,179,869,184          &   0.00000018626451\%\\
    34,359,738,368          &   0.00000074505805\%\\
    68,719,476,736          &   0.00000298023219\%\\
    137,438,953,472         &   0.00001192092824\%\\
    274,877,906,944         &   0.00004768370445\%\\
    549,755,813,888         &   0.00019073468138\%\\
    1,099,511,627,776       &   0.00076293654275\%\\
    2,199,023,255,552       &   0.00305171124684\%\\
    4,398,046,511,104       &   0.01220628622226\%\\
    8,796,093,022,208       &   0.04881620601105\%\\
    17,592,186,044,416      &   0.19512188925244\%\\
    35,184,372,088,832      &   0.77820617397564\%\\
    70,368,744,177,664      &   3.07667655236558\%\\
    140,737,488,355,328     &  11.75030974154045\%\\
    281,474,976,710,656     &  39.34693402873665\%\\
    562,949,953,421,312     &  86.46647167633872\%\\
    1,125,899,906,842,624   &  99.96645373720974\%\\
    2,251,799,813,685,248   &  99.99999999999873\%\\
    4,503,599,627,370,496   & 100.00000000000000\%
    \end{tabular}
    \doublespacing
    \caption{The probability of a hash collision when the number of entities reaches different stages, given 12 byte hash IDs.}
    \label{bday}
\end{figure}

Unfortunately, MySQL doesn't have a native 12 byte number type, so the
ID column on each table in this project uses the type {\tt DEC(30)},
which is not as performant as a {\tt BIGINT}, and lacks certain
functionality, such as bitwise operations.  Another frustration is that
{\tt DEC(30)} usually maps to a string instead of a big integer in
various programming environments.  For this reason, in hindsight, and
in future projects, {\tt BIGINT} (8 bytes) is recommended.

Using the hashed ID method outlined here, with 8 bytes
the probability of a hash collision in a database of up to 4,294,967,296
identifiable entities is roughly 39\%.  In any case, a few hash
collisions is arguably acceptable in the area of news aggregation
(as opposed to, say, the area of banking).
