\section{Terminology}

Some news related and technical terminology are used throughout this
dissertation.  These terms will now be introduced.

\paragraph{Class} This term is used to mean some boolean or label
that can be applied to a document.  In most cases, boolean classes
({\it true} or {\it false}) are used instead of labels (many-valued
logic).  Though it is common to represent a document's class as a
real number between 0 and 1, 0 being {\it false} and 1 being
{\it true}.
\paragraph{False positive}
This defines a situation when a positive classification is made
incorrectly, e.g. when some fact is said to be true for a document,
when the fact does not actually hold true for that document.
\paragraph{False negative}
This defines a situation when a negative classification is made
incorrectly, e.g. when we {\it miss} a document for which a fact
would true.
\paragraph{True positive and true negative} As the names suggest, these
two terms indicate when a classification is made ({\it true} or
{\it false}), and the classification is correct.
\paragraph{News index}  This refers to certain kinds of webpages
that list a number of news items.  The category webpages within a
news website ({\it World}, {\it Sport}, etc.) are examples of
news indices.
\paragraph{News item}  This refers to webpages that contain news in
some longform way (a few paragraphs, a headline, etc.). 
The term {\it article} is avoided since it relates mostly to newspapers,
and \nr{} aims to process news from a broader category of online media.
\paragraph{Precision} This is the rate of accuracy within positive
classifications.  It can best be understood as a question: ``If
a classifier labels an item as positive, what is the likelihood
the correct label is in fact {\it positive}?''
\paragraph{Recall} The ratio of items correctly classified as positive
to the actual total of positives.  This measures how well a
classification system performs at the task of exhaustively finding
all positive items in a dataset.
\\\\
\noindent Accuracy is another popular term in machine learning (correct
classifications over total classifications), but that term is avoided
in this dissertation, because it can be misleading when classes are
not evenly distributed.  For example, a classifier that says
everything is a positive match would perform with 95\% accuracy
when 95\% of items just happen to be positive matches.